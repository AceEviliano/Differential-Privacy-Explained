{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment you will implement logistic regression model for classifying cat vs non-cat images. First, let's import required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py # for processing files stored in h5 format\n",
    "import matplotlib # for plotting\n",
    "from matplotlib import pyplot as plt # for plotting\n",
    "from PIL import Image # for image processing\n",
    "\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data consists of a set of cat and non-cat images along with the corresponding labels. Test labels can be used for quantifying the performance of the model. The train and test data are stored in h5 format. So we will use file reader from h5py package and convert the data to numy array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_data():\n",
    "    train_dataset = h5py.File('datasets/train_catvnoncat.h5', \"r\")\n",
    "    train_x = np.array(train_dataset[\"train_set_x\"][:]) # train images\n",
    "    train_y = np.array(train_dataset[\"train_set_y\"][:]) # train labels\n",
    "    return train_x, train_y\n",
    "    \n",
    "def load_test_data():\n",
    "    test_dataset = h5py.File('datasets/test_catvnoncat.h5', \"r\")\n",
    "    test_x = np.array(test_dataset[\"test_set_x\"][:]) # test images\n",
    "    test_y = np.array(test_dataset[\"test_set_y\"][:]) # test labels\n",
    "    return test_x, test_y\n",
    "\n",
    "train_x, train_y = load_train_data()\n",
    "test_x, test_y = load_test_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets print the size of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'train data size: train_x {train_x.shape}, train_y {train_y.shape}')\n",
    "print(f'test data size: test_x {test_x.shape}, test_y {test_y.shape}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, there are 209 training images with labels and 50 test images. Each image is a color image of size 64 x 64. Now lets plot a few training images picked randomly along with its labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_to_name = {1:'cat', 0:'not-a-cat'}\n",
    "fig = plt.figure(figsize = (12, 12))\n",
    "rows, columns = 4, 4\n",
    "\n",
    "for i in range(1, rows*columns+1):\n",
    "    axes = fig.add_subplot(rows, columns, i)\n",
    "    image_index = np.random.randint(train_x.shape[0])\n",
    "    plt.imshow(train_x[image_index])\n",
    "    axes.set_xticks([])\n",
    "    axes.set_yticks([])\n",
    "    plt.xlabel(class_to_name[train_y[image_index]])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently each training is 64 x 64 x 3 i.e train_x has shape (m, 64, 64, 3) where m is number of training samples. We need the train_x to have shape nx x m where nx is the number of input features ie 64*64*3 = 12288. You are required to complete the function flatten below that will take a m x h x w x c numpy array, flatten it to (h*w*c) x m numpy array and return it. Hint: numpy.reshape method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(z):\n",
    "    m, h, w, c = z.shape\n",
    "    nx = h*w*c\n",
    "    ###Fill your code below. ###    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can test your function by uncommenting the following line.\n",
    "# print(flatten(train_x).shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that data is ready, you will implement logistic regression. You may look at the python style pseudo-code in lecture notes for clarity. The code below will mostly follow that pseudo-code. You have to complete forward, backward and sigmoid functions below. Further you have to complete few lines in the train loop in main function that trains the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(a, w, b):\n",
    "    \"\"\"\n",
    "      Forward propagates a through the logistic unit given w and b\n",
    "      a: I/p to logistic unit of shape nx x m\n",
    "      w: weight vector of shape nx x 1\n",
    "      b: bias which is a scalar\n",
    "      \n",
    "      returns anew: the output from logistic unit of shape 1 x m\n",
    "              cache: a tuple that contains input a\n",
    "    \"\"\"\n",
    "    \n",
    "    # fill rhs of following 3 lines. no extra lines of code required.\n",
    "    z =                 # linear computation; np.dot or np.matmul or the operator @ will be helpful\n",
    "                        # learn about numpy broadcasting; it will be helpful for adding b to dot product of w and a\n",
    "        \n",
    "    anew =             # non-linear activation on z\n",
    "    cache =           # a tuple that contains input a\n",
    "    return anew, cache\n",
    "\n",
    "def backward(da, a, cache):\n",
    "    \"\"\"\n",
    "      Backward propagates da through the logistic unit given a and cache\n",
    "      da: derivative of loss with respect to logistic output; shape is 1 x m\n",
    "      a: o/p to logistic unit of shape 1 x m\n",
    "      cache: a tuple that contains input to logistic unit; i/p to logistic unit is of shape nx x m\n",
    "      \n",
    "      returns dw: derivative of loss with respect to w; shape is nx x 1\n",
    "              db: derivative of loss with respect to b; db is a scalar\n",
    "    \"\"\"\n",
    "    \n",
    "    # fill rhs of following 4 lines. no extra lines of code required.\n",
    "    aprev =                     # extract from cache the i/p to logistic unit\n",
    "    dz =                        # compute dz using chain rule as product of incoming grad da and local grad \n",
    "    dw =                        # compute dw; np.sum will be helpful  \n",
    "    db =                        # compute db; np.sum will be helpful   \n",
    "    return dw, db\n",
    "\n",
    "def sigmoid(z):\n",
    "    \"\"\"\n",
    "      Computes sigmoid of the given np array z\n",
    "      z: np array of any shape\n",
    "      \n",
    "      returns sigmoid of z\n",
    "    \"\"\"\n",
    "    # replace ...... below by correct return value; np.exp will be helpful\n",
    "    return ......\n",
    "\n",
    "def main(): # main function to train the model\n",
    "    # load train data\n",
    "    a0, y = load_train_data()\n",
    "    a0 = flatten(a0)\n",
    "    a0 = a0/255. # normalize the data to [0, 1]\n",
    "    nx, m = a0.shape    \n",
    "    \n",
    "    # set some hyperparameters and epsilon\n",
    "    alpha = 0.01    \n",
    "    miter = 500\n",
    "    epsilon = 1e-6\n",
    "    \n",
    "    #intialize weight and bias parameters\n",
    "    w = np.random.randn(nx, 1)*.01\n",
    "    b = 0\n",
    "    \n",
    "    # train loop\n",
    "    # fill rhs in the body of the for loop\n",
    "    for i in range(miter):\n",
    "        a1, cache =             # forward propagation        \n",
    "        L =                     # compute loss; np.sum or np.mean, np.log will be useful\n",
    "        da1 =                   # derivative of loss with respect to a1\n",
    "        dw, db =                # backward propagation\n",
    "        w -=                    # update w\n",
    "        b -=                    # update b\n",
    "        if not i%100: # print loss every 100 iterations\n",
    "            print(f'Loss at iteration {i}:\\t{np.asscalar(L):.4f}')\n",
    "        \n",
    "    return w, b\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    w, b = main()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will test our model on both train and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x, w, b):\n",
    "    a = sigmoid( w.T @ x + b)\n",
    "    predictions = np.zeros_like(a)\n",
    "    predictions[a > 0.5] = 1\n",
    "    return predictions\n",
    "\n",
    "def test_model(x, y, w, b):\n",
    "    predictions = predict(x, w, b)\n",
    "    acc = np.mean(predictions == y)\n",
    "    acc = np.asscalar(acc)\n",
    "    return acc\n",
    "\n",
    "x, y = load_train_data()\n",
    "x = flatten(x)\n",
    "x = x/255. # normalize the data to [0, 1]\n",
    "print(f'train accuracy: {test_model(x, y, w, b) * 100:.2f}%')\n",
    "\n",
    "x, y = load_test_data()\n",
    "x = flatten(x)\n",
    "x = x/255. # normalize the data to [0, 1]\n",
    "print(f'test accuracy: {test_model(x, y, w, b) * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions\n",
    "1. Can you bring down the loss more? (Hint: Try more iterations. If loss oscillates, try different learning rates)\n",
    "2. Write a simple python code to plot loss against number of iterations for learning rate alpha = 0.005. State your observations from the plot.\n",
    "3. What happens to the model if weights are intialized to zero? Explain your observations.\n",
    "4. What is the range of probabilities for cat images in the test data? What is the range of probabilities for cat images in the train data? How do they compare?\n",
    "\n",
    "Note: All questions will be answered in the jupyter notebook only. Wherever code is required you write and run the code in a code cell. For text, write and render in a markdown cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
